---
title: "Desafio Oncase - Receitas"
output:
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
---

# Introdução

askjdhajshdajskd

## Preparação das ferramentas e dos dados
Inicialmente vamos instalar todos os pacotes necessários para as análises, mudar o diretório de trabalho e tratar os dados através de limpeza e criação de features.

## Instalação dos pacotes necessários
```{r}
start <- Sys.time()
```

```{r}
#install.packages('jsonlite')
#install.packages('udpipe')
#install.packages('textrank')
#install.packages('rpart')
#install.packages('rattle')

```

Uma vez que os pacotes foram instalados precisamos deixá-los disponíveis para o uso.

```{r, results = 'hide', message =  FALSE, include = FALSE}
library(jsonlite)
library(plyr)
library(dplyr)
library(ggplot2)
library(stringr)
library(tibble)
library(udpipe)
library(textrank)
library(tm)
library(GGally)
library(rpart)
library(rattle)
```

## Leitura dos dados
A leitura dos dados é feita pelo pacote jsonlite e transformado num `data.frame`. Dessa forma, cada coluna descreve uma variável.

```{r}
setwd("G:/Dropbox_Novo/Dropbox/selecao_oncase/selecao_oncase")
receitas <- fromJSON('receitas.json')
```

INICIO LEMBRAR DE REMOVER
```{r}
#set.seed(1)
#receitas <- receitas[sample(seq_along(receitas$fat), 2000, replace = FALSE), ]
```
FIM LEMBRAR  DE REMOVER

# Análise descritiva preliminar

Para as variáveis contínuas nós calculamos as principais medidas resumo. No entando, é possível observar que há um valor extremamente fora do esperado para cada variável, este valor pode indicar algum erro de medição visto que a distância do terceiro quartil é muito grande, o que não configura um outlier, mas um erro claro de medição.

```{r}
receitas %>% select(rating, fat, calories, protein, sodium) %>% summary()
```

Criamos uma variabel `id` para identificar qual indivíduo apresenta erro de medição. A partir dela conseguimos identifica um indivíduo altamente discrepante, o indivíduo `666`.

```{r}
receitas <- receitas %>% mutate(id = seq_along(fat))
id_error <- receitas %>% select(fat, calories, protein, sodium) %>% apply(2, which.max)
id_error
```

Além do indivíduo `666` podemos observar outros valores estranhos nas variáveis contínuas, a saber: `fat, calories, protein` e `sodium`. Estes valores tem deformado a distribuição de probabilidade conforme podemos observar nos boxplots abaixo.

```{r}
receitas[-id_error[1], ] %>% ggplot(aes(y = fat)) + geom_boxplot()
receitas[-id_error[2], ] %>% ggplot(aes(y = calories)) + geom_boxplot()
receitas[-id_error[3], ] %>% ggplot(aes(y = protein)) + geom_boxplot()
receitas[-id_error[4], ] %>% ggplot(aes(y = sodium)) + geom_boxplot()
```


## Imputação de dados

Então, nós utilizamos fontes nutricionais externas para detectar estes valores discrepantes para cada variável descrita. Todas medidas consideram a média ingerida por uma pessoa por dia. Obviamente esta medida pode ser subestimada, pois dependende diretamente do tamanho da porção que serve cada receita e sobrestimada considerando que as métricas são diárias e não por refeição/receita. Dessa forma, supomos que há um equilíbrio nas métricas externas utilizadas. Além disso, se usarmos essa média estaremos excluindo os outliers da análise e isto pode diminuir a capacidade de generalização do modelo então, usaremos duas vezes a média recomendada. Em detalhes, são elas:

* Total de gordura (`fat`) - Segundo a [Health](https://health.gov/dietaryguidelines/dga2000/document/choose.htm) a média de gordura para uma dieta diária de 2.800 calorias é de 93g. Baseado nessa informação trataremos 186g de gordura como limiar.

* Calorias (`calories`) - Ainda de acordo com a [Health](https://health.gov/dietaryguidelines/2015/guidelines/appendix-2/) a média de calorias para um homem e uma mulher de um jovem é 2.800 e 2200 calorias, respectivamente. Devido a ausência do gênero como variável utilizaremos 5000 calorias como limiar.

* Proteína (`protein`) - Em entrevista para o [NY Times](https://www.nytimes.com/2017/07/28/well/eat/how-much-protein-do-we-need.html) a autora do livro “Devoured: How What We Eat Defines Who We Are”, Sophie Egan afirma que em média um norte americano consome em média 100g de proteínas pode dia logo, o limiar adotado é 200g. 

* Total de Sódio (`sodium`) - A American Heart Association conhecida como [Heart](https://www.heart.org/en/healthy-living/healthy-eating/eat-smart/sodium/how-much-sodium-should-i-eat-per-day) informam que os americanos consomem em média 3.400mg de sódio por dia assim, o valor limitante para definição de erro de medida ou não é 6.800mg.


Em outras palavras, receitas que ultrapassem os limiares citados acima, nas suas respectivas variáveis, serão substituídas pela média truncada em 5%. 


```{r}
sum(na.omit(receitas$fat) >= 93)
sum(na.omit(receitas$calories) >= 2500)
sum(na.omit(receitas$protein) >= 100)
sum(na.omit(receitas$sodium) >= 3400)

id_error_fat <- which(receitas$fat >= 93)
id_error_calories <- which(receitas$calories >= 2500)
id_error_protein <- which(receitas$protein >= 100)
id_error_sodium <- which(receitas$sodium >= 3400)

```

```{r}
fat_trim_mean <- mean(receitas$fat, na.rm = TRUE, trim = .05)
calories_trim_mean <- mean(receitas$calories, na.rm = TRUE, trim = .05)
protein_trim_mean <- mean(receitas$protein, na.rm = TRUE, trim = .05)
sodium_trim_mean <- mean(receitas$sodium, na.rm = TRUE, trim = .05)

fat <- ifelse(is.na(receitas$fat), fat_trim_mean, receitas$fat)
calories <- ifelse(is.na(receitas$calories), fat_trim_mean, receitas$calories)
protein <- ifelse(is.na(receitas$protein), fat_trim_mean, receitas$protein)
sodium <- ifelse(is.na(receitas$sodium), fat_trim_mean, receitas$sodium)

fat[id_error_fat] <- fat_trim_mean
calories[id_error_calories] <- calories_trim_mean
protein[id_error_protein] <- protein_trim_mean
sodium[id_error_sodium] <- sodium_trim_mean


```


## Criação de novas features

Acreditamos que a nota da receita está relacionada a dificuldade da mesma, pois receitas muito difíceis podem não concluída com sucesso e com isso ter sua nota diminuída. Então, elencamos algumas medidas para avaliar a dificuldade da receita, são elas: (1) número de processos (`num_process`); (2) cozida, assada, ou vai ao forno (`baked`); (3) número de caracteres (concisão) (`conciseness`); (4) preparation time (`time`).

```{r}
num_process <- sapply(receitas[[1]], function(x) length(x))
baked <- str_detect(receitas$directions, '°F|°C|°K')
conciseness <- str_length(receitas$directions)

hour <- sapply(str_extract_all(receitas$directions, "\\d+(?=\\shour)"),
               function(x) sum(as.numeric(x))) 
minutes <- sapply(str_extract_all(receitas$directions, "\\d+(?=\\sminute)"),
               function(x) sum(as.numeric(x)))
time <- 24 * hour + minutes
```

Número de dias desde a publicação da receita pode ser um fator decisivo na nota da receita. Além disso, criamos uma variável que determina se uma "receita é clássica" ou não, elas são consideradas clássicas se tem mais de 10 anos (3650 dias). Através de uma variável dummy `old_recipe` sabemos se as receitas são clássicas ou não.

```{r}
date <- receitas %>% mutate(date, date1 = as.Date(date)) %>% select(date1)
num_days <- as.numeric(Sys.Date() - date$date1)
num_days[which(is.na(num_days))] <- mean(num_days, na.rm = TRUE)
old_recipe <- (num_days >= 3650) %>% as.integer() %>% as.factor()
```

Outra importante variável para a nota da receita são as categorias que ela está inserida. Nós calculamos e armazenamos o número de categorias em que uma receita está inserida (`num_categories`) e verificamos também se está é vegetariana ou não (`vegetarian`). Além disso, verificamos quais as categorias são mais frequentes nas receitas através da variável `freq_cat`

```{r}
num_categories <- sapply(receitas$categories,
                         function(x) length(x))

vegetarian <- receitas %>% 
  select(categories) %>% 
  sapply(function(x) str_detect(x, pattern = 'Vegetarian')) %>% 
  as.integer() %>% as.factor()

cat <- sapply(receitas$categories, 
              function(x) stringi::stri_trans_general(x, "Latin-ASCII")  )

freq_cat <- factor(unlist(receitas$categories), 
                         levels = unique(unlist(receitas$categories)))
summary(freq_cat) %>% head(10)


```

A descrição da receita funciona como um subtítulo da receita e pode ser um fator e engajamento a executar a receita. Dessa forma, pode ter influência sobre a avaliação da receita. Portanto, três variáveis foram criadas, a primeira verifica se há descrição na receita, a segunda indica o número de orações de sentido completo na descrição e a terceira revela o número de caracteres na descrição. Elas são descritas pelas variáveis `desc`, `phrases` e `desc_char`, respectivamente.

```{r}
desc <- receitas %>% select(desc) %>% is.na() %>% as.numeric()

phrases <- receitas %>% 
  select(desc) %>% 
  apply(1, 
        function(x) str_count(x, pattern = '\\.|\\:|\\?|\\!|\\;'))
phrases <- ifelse(is.na(phrases), 0, phrases)

desc_char <- receitas %>% select(desc) %>% apply(1,
                                                function(x) str_length(x)) 
desc_char <- ifelse(is.na(desc_char), 0, desc_char)
```


Estudando a variável ingredientes podemos detectar que algumas receitas não apresentam nenhum ingrediente assim, não foram consideradas receitas válidas e foram deletadas do banco de dados. Para execução do processo de deleção utilizamos a variável `rwi` que significa "recipes wihtout ingredients". A base de dados `receitas2` armazena a nova base de dados sem as receitas inválidas. Em seguida, contamos o número de ingredientes por receita.

```{r}
rwi <- which(sapply(receitas$ingredients, length) == 0)
rwi
receitas2 <- receitas[-rwi, ]

num_ingredients <- receitas2$ingredients %>% sapply(function(x) length(x))
```


```{r}
drop_words <- c('cup', 'cups', 'teaspoon', 'teaspoons', 'tablespoons', 'tablespoon',
                'peel', 'pound', 'ground', 'preserve', 'inch', 'piece', 'stick', 'slice',
                'large', 'optional', 'ounce', 'leave', 'purpose', 'powder', 'broth',
                'baking', 'ounces', 'pieces')


ingredients <- receitas2$ingredients %>% 
  lapply(function(x) removeWords(x, drop_words)) %>% 
  lapply(function(x) removeWords(x, stopwords('english'))) %>% 
  lapply(function(x) str_replace_all(x, '[^[:alnum:]]', ' ')) %>% 
  lapply(function(x) removeNumbers(x)) %>% 
  lapply(function(x) stripWhitespace(x))


#Dowload deve ser feito uma única vez
#ud_model_temp <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model('english-ewt-ud-2.4-190531.udpipe')

x <- udpipe_annotate(ud_model, x = unlist(ingredients))
x <- as.data.frame(x)

stats <- subset(x, upos %in% "NOUN")
stats <- txt_freq(x = stats$lemma)
library(lattice)
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = head(stats, 30), 
         col = "cadetblue", main = "Most occurring nouns", xlab = "Freq")

```

A variável resposta tem algumas notas (`rating`) faltando, supondo que esta ausência é aleatória, imputamos estes valores pela média. Além disso, observamos que há uma assimetria positiva na variável resposta, notamos também que a nota mínima recebida por uma receita é zero e máxima igual a 5.0.

```{r}
receitas2 %>% 
  select(rating) %>% 
  summary()

receitas2 <- receitas2 %>% mutate(rating, rating = ifelse(is.na(rating), 
                                             mean(rating, na.rm = TRUE), rating))

receitas2 %>%
  ggplot(aes(rating)) + geom_histogram(bins = 6) + ylab('Frequency') + theme_bw()
```

Através das variáveis contínuas e das criadas neste estudo (features) montamos um novo dataset denominado de  `recipes3`. Com este novo dataset estudamos quais variáveis podem influenciar na nota de uma receita.

```{r}
library(data.table)
recipes3 <- data.table(receitas2$rating, fat[-rwi], calories[-rwi], 
                       protein[-rwi], sodium[-rwi], num_categories[-rwi],num_days[-rwi],
                       num_ingredients, num_process[-rwi], baked[-rwi], 
                       conciseness[-rwi], desc[-rwi], desc_char[-rwi], old_recipe[-rwi], 
                       phrases[-rwi], time[-rwi], vegetarian[-rwi], 
                       receitas2$categories)

names(recipes3) <- c('rating', 'fat', 'calories', 'protein', 'sodium', 'num_categories',
                     'num_days', 'num_ingredients', 'num_process', 'baked', 
                     'conciseness', 'desc', 'desc_char', 'old_recipe', 'phrases',
                     'time', 'vegetarian', 'categories')

recipes3$desc <- recipes3$desc %>% 
  as.integer() %>% 
  as.factor() 

recipes3$baked <- recipes3$baked %>% 
  as.integer() %>% 
  as.factor() 

```


```{r, results = 'hide', message =  FALSE, include = FALSE}
#library(GGally)
#p <- recipes3[, -c(10, 12, 14, 17)] %>% ggpairs()
#p
```


```{r}
recipes3 %>% dplyr::select(-c(categories)) %>% summary()
```

As 10 receitas com maior teor calórico são descritas abaixo.

```{r}
caloric_recipes <- recipes3 %>% 
  arrange(desc(calories)) %>% slice(1 : 10)
caloric_recipes
```

Considerando as 10 receitas com maior teor calórico verificamos as principais categorias que estas receitas pertencem, respectivamente, são: (1) Peanut Free; (2) Soy Free; (3) Tree Nut Free; (4) Dinner; (5) Vegetarian; (6) Pescatarian; (7) Kosher; (8) Bon Appétit; (9) Party; (10) Sugar Conscious.

```{r}
stats <- txt_freq(unlist(caloric_recipes$categories))
library(lattice)
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = head(stats, 10), 
         col = "cadetblue", main = "Categorias mais frequentes", xlab = "Frequência")
stats %>% slice(1 : 10)
```

Seguindo o conceito da fronteira de Pareto, recomendamos três receitas segundo 5 critérios por ordem de prioridade, a saber: (1) maiores notas; (2) baixo teor de gordura; (3) baixo teor de calorias; (4) pouco sódio; (5) poucos processos; (6) receita simples (consisa).

```{r}
recipes3[with(recipes3, order(-rating, fat, calories, sodium,
                              num_process, conciseness)), ] %>% 
  add_column(title = receitas$title[-rwi]) %>% 
  slice(1 : 3)

```


# Modelagem 
```{r}
recipes4 <- recipes3 %>% 
  mutate(rating, rating = ifelse(rating >= 4.0, 1, 0) %>% as.factor())
```

Através da extração de regras de uma árvore de decisão notamos que 

```{r}
fit_tree <- rpart(formula = rating ~., 
                  data = recipes4 %>% 
                    dplyr::select(-categories))
plot(fit_tree)
text(fit_tree, cex = .8)

asRules(fit_tree)
```
 

```{r}
recipes_top100 <- recipes3 %>% 
  arrange(desc(rating)) %>% 
  add_column(title = receitas$title[-rwi]) %>% 
  slice(1 : 100)
recipes_top100
```

```{r}
Sys.time() - start
```

